{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# DataCleaning (Class Data)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "#import required modules:\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime, timezone\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "import seaborn as sns\n",
    "import os\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "import copy\n",
    "\n",
    "plt.style.context('dark_background')\n",
    "plt.rcParams.update(plt.rcParamsDefault)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## <span style=color:#7fc97f>Description of the Class Data</span>\n",
    "#### The class has 2 inputs: A Pandas DataFrame and a name:\n",
    "\n",
    "--> To create an instance ot the Class Data, use following lines:\n",
    "```json\n",
    "dataframe = pd.read_csv(\"PATH TO DATA\")\n",
    "name=\"DESIRED NAME\"\n",
    "LakeAegeri=Data(dataframe,name)\n",
    "```\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "#### <span style=color:#7fc97f>The Class has various methods:</span> <br>\n",
    "#####  <span style=color:#386cb0>1. The INSTANCE_CLASS_DATA.calc_rolling_statistics(column,window,plot=\"n\",save_plot=\"n\")</span>\n",
    "This method will calculate the rolling statistics and outputs a plot.\n",
    "\n",
    "If you don't want the plot plotted in the notebook, use show_plot=\"n\".\n",
    "\n",
    "If you want to save the plot in the /data/output/.. folder:\n",
    "- save_plot=\"y\" -> It asks you to input a name without a space.\n",
    "- save_plot=\"CUSTOM_NAME\" -> It creates a plot with the name CUSTOM_NAME in the specified folder\n",
    "- save_plot=\"n\": It will not save the created figure\n",
    "If you want to define the rolling window, use window=INTEGER\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "##### <span style=color:#386cb0>2. The INSTANCE_CLASS_DATA.check_stationarity(column):</span>\n",
    "This method will check the stationarity using the Augmented Dickey-Fuller Test (ADF). As an input use the column you want the stationarity checked on.\n",
    "We dont need this method.\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "##### <span style=color:#386cb0>3. INSTANCE_CLASS_DATA.detect_outlier(self, column, pchip_imputation=\"y\", PERIOD=24, display_plots=\"y\"):</span>\n",
    "\n",
    "This method will clean the data with help of the seasonal decomposition of the specified column (column=COLUMN_NAME).<br>\n",
    "\n",
    "The method returns an instance of the class Data (with the whole DataFrame with the (timeseries) cleaned column). The physical impossible outliers are not cleaned in this method.<br>\n",
    "\n",
    "If you want the more \"fancy\" PChip (Piecewise Cubic Hermite Interpolating Polynomial) Imputation, use pchip_imputation=\"y\". It looks at outlier and puts a mathematical function over the dataset. The method estimates values that minimize overall curvature, thus obtaining a smooth surface passing through the input points. Spline interpolation is computationally efficient and can be used to interpolate large datasets quickly and accurately. Otherwise, use pchip_imputation=\"n\" to use the simple imputer: It looks at the normalized residuals and sets >3 values to 3 and <-3 values to -3. In the last step. If you want to delete the outliers, use pchip_imputation=\"delete\". Note, that many data is lost due to this process, because it will delete the entire column.<br>\n",
    "\n",
    "PERIOD: If you want to change the period of the data, change the PERIOD parameter.<br>\n",
    "\n",
    "Display plots in the notebook: If you want to display the plots, use display_plots=\"y\", else display_plots=\"n\"\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "##### <span style=color:#386cb0>4. INSTANCE_CLASS_DATA.remove_outliers_temperature(self, skin_column_name=\"y\", bulk_column_name=\"y1\", airtemp_column_name=\"air_temp\", imputation=\"y\"):</span>\n",
    "\n",
    "This method will clean the physically impossible outliers of the skin, bulk and air temperatures.\n",
    "\n",
    "skin_column_name=\"XXX\" : input the name of the skin temperature column\n",
    "bulk_column_name=\"XXX\" : input the name of the bulk temperature column\n",
    "airtemp_column_name=\"XXX\" : input the name of the air temperature column\n",
    "\n",
    "imputation=\"y\": If you want the physically impossible values imputed, make imputation=\"y\". The imputation method is the PChip (Piecewise Cubic Hermite Interpolating Polynomial) method. It looks at outlier and puts a mathematical function over the dataset. The method estimates values that minimize overall curvature, thus obtaining a smooth surface passing through the input points. Spline interpolation is computationally efficient and can be used to interpolate large datasets quickly and accurately.\n",
    "imputation=\"n\": If you want the physically impossible values deleted, use imputation=\"n\". Note, that many data is lost due to this process, because it will delete the entire column.\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "##### <span style=color:#386cb0>5. Instance_CLASS_DATA.remove_outliers_static(self, column_name, imputation=\"y\"):</span>\n",
    "\n",
    "This method will remove the statistical outliers of a column. Note, that this column will not look at the seasonality in the data, and will use the normalized values of the selected column (column_name=\"XXX\") to determine the outliers.\n",
    "\n",
    "If the Z-Score (COLUMN_VALUE-mean/std) exceeds 3 (or -3), the point will be considered as an outlier.\n",
    "-> If you want to impute the missing data with the Splines Imputation, use imputation = \"y\", else imputation = \"n\". The  PChip (Piecewise Cubic Hermite Interpolating Polynomial) Imputation looks at the missing points (here the outliers) and puts a mathematical function over the dataset. The method estimates values that minimize overall curvature, thus obtaining a smooth surface passing through the input points.  PChip interpolation is computationally efficient and can be used to interpolate large datasets quickly and accurately.\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "##### <span style=color:#386cb0>6. Instance_CLASS_DATA.rename_columns(self,columns={\"y\": \"skin_temp\", \"y1\": \"bulk_temp\"}): </span>\n",
    "\n",
    "This method will rename the columns of the instance. With a dictionary, the columns can be added by {\"name_before\":\"name_after\",...}\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "##### <span style=color:#386cb0>7. Instance_CLASS_DATA.create_histogram(self,column_name): </span>\n",
    "This method creates a histogram from the selected column. It also adds the Kernel Denstity Estimation (KDE) onto the histogram.\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "##### <span style=color:#386cb0>8. create_paiplot(self,column_names=[]) </span>\n",
    "This method will create a pairplot of the selected columns (column_names=[\"column1\",\"column2\",...]). <br> If the parameter column_names is not defined, the whole dataset will be plotted as a pairplot.\n",
    "<br>\n",
    "<br>\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "class Data:\n",
    "    def __init__(self, dataframe, name, set_index_datetime_int=\"y\"):\n",
    "        self.name = name\n",
    "        self.dataframe = dataframe\n",
    "        #convert the strings and add the datetime column to index\n",
    "        self.dataframe[\"datetime\"] = pd.to_datetime(self.dataframe[\"datetime\"])\n",
    "\n",
    "        index_name = self.dataframe.index.name  #this is used further below in the else: statement\n",
    "        self.dataframe = self.dataframe.reset_index()\n",
    "\n",
    "        if set_index_datetime_int == \"y\":\n",
    "            self.dataframe.index = self.dataframe[\"x\"]\n",
    "            self.dataframe = self.dataframe.drop(columns=[\"x\", \"index\"])\n",
    "        else:\n",
    "            self.dataframe.index = self.dataframe[index_name]\n",
    "            self.dataframe = self.dataframe.drop(columns=[index_name])\n",
    "\n",
    "        self.columns = self.dataframe.columns\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"DataFrame {name} with columns: {str(list(self.columns))}\"\n",
    "\n",
    "    def calc_rolling_statistics(self, column, window, show_plot=\"no\", save_plot=\"no\"):\n",
    "        mean_rm = self.dataframe[column].rolling(window=window).mean()\n",
    "        std_rm = self.dataframe[column].rolling(window=window).std()\n",
    "\n",
    "        plt.style.context\n",
    "        plt.rc('figure', figsize=(10, 6))\n",
    "        fig, ax = plt.subplots(1, sharex=False, sharey=False)\n",
    "        ax.plot(self.dataframe[\"datetime\"], self.dataframe[column], color='#e31a1c', label='Actual', alpha=0.7)\n",
    "        ax.plot(self.dataframe[\"datetime\"], mean_rm, color='#b2df8a', label=f'Rolling Mean (window: {window})',\n",
    "                alpha=0.7)\n",
    "        ax.plot(self.dataframe[\"datetime\"], std_rm, color='#1f78b4', label=f'Rolling Std (window: {window})', alpha=0.7)\n",
    "        plt.legend(loc='best')\n",
    "        plt.title(f'Rolling Mean & Standard Deviation of {column}')\n",
    "\n",
    "        if save_plot == \"y\":\n",
    "            plt.savefig(f\"./data/output_png/{input('How should the figure be named? (no Spaces!)')}.png\")\n",
    "        elif save_plot != \"no\":\n",
    "            plt.savefig(f\"./data/output_png/{save_plot}.png\")\n",
    "\n",
    "        if show_plot == \"n\":\n",
    "            plt.close()\n",
    "        plt.show(block=False)\n",
    "\n",
    "    def check_stationarity(self, column):\n",
    "        print(f\"Visual check is advised with {self.name}.calc_rolling_statsitics(...,plot='Y')\")\n",
    "        print(\n",
    "            \"->  A stationary Time Series is one which characteristics like mean and variance does not change over time.\")\n",
    "        print(\n",
    "            \"Another way of checking for stationarity of the time series is using Augmented Dickey-Fuller (ADF) Test to check stationarity:\")\n",
    "        print(\"--------------------\")\n",
    "        print('Dickey-Fuller Test: ')\n",
    "        X = self.dataframe[column].dropna().values\n",
    "        dftest = adfuller(X, autolag='AIC')\n",
    "        dfoutput = pd.Series(dftest[0:4], index=['Test Statistic', 'p-value', 'Lags Used', 'No. of Obs'])\n",
    "        for key, value in dftest[4].items():\n",
    "            dfoutput['Critical Value (%s)' % key] = value\n",
    "\n",
    "        if list(dfoutput.items())[1][1] > 0.05:\n",
    "            print(\n",
    "                f\"with a p-value of {round(list(dfoutput.items())[1][1], 3)}, we fail to reject the null hypothesis, that the data is stationary.\")\n",
    "            print(dfoutput)\n",
    "            return False\n",
    "        else:\n",
    "            print(\n",
    "                f\"with a p-value of {round(list(dfoutput.items())[1][1], 3)}, we reject the null hypothesis, that the data is stationary.\")\n",
    "            print(dfoutput)\n",
    "\n",
    "    def detect_outlier(self, column, pchip_imputation=\"y\", PERIOD=24, display_plots=\"y\"):\n",
    "        ### 1. Prepare Dataset for the seasonal seasonal_decompose function:\n",
    "        pd.set_option('display.max_rows', None)\n",
    "        dataframe_noNAN = self.dataframe.dropna()\n",
    "        dataframe_noNAN = dataframe_noNAN.reset_index()\n",
    "        dataframe_noNAN = dataframe_noNAN.set_index(\"datetime\")\n",
    "\n",
    "        #set plot size:\n",
    "        plt.rc('figure', figsize=(10, 6))\n",
    "        plt.rc('font', size=10)\n",
    "\n",
    "        ### 2. Seasonal decompose\n",
    "        result = seasonal_decompose(dataframe_noNAN[[column]], period=PERIOD, model=\"additive\")\n",
    "\n",
    "        #plot the seseasonal_decompose:\n",
    "        fig, ax = plt.subplots(4, sharex=False, sharey=False)\n",
    "        fig.subplots_adjust(bottom=7, top=9)\n",
    "\n",
    "        ax[0].plot(result.observed, color=\"#a6cee3\", linewidth=1)\n",
    "        ax[0].set_title(\"Result observed\")\n",
    "\n",
    "        ax[1].plot(result.seasonal, color=\"#b2df8a\", linewidth=1)\n",
    "        ax[1].set_title(f\"seasonality of Period {PERIOD}\")\n",
    "\n",
    "        ax[2].plot(result.trend, color=\"#fb9a99\", linewidth=1)\n",
    "        ax[2].set_title(\"Trend\")\n",
    "\n",
    "        ax[3].plot(result.resid, color=\"#fdbf6f\", linewidth=1)\n",
    "        ax[3].set_title(\"Residuals\")\n",
    "\n",
    "        if display_plots != \"y\":\n",
    "            plt.close()\n",
    "        plt.show()\n",
    "\n",
    "        ## 2.1 residuals (imputation yes or no)\n",
    "        seasonal_df = result.seasonal.to_frame()\n",
    "        trend_df = result.trend.to_frame()\n",
    "        residuals_df = result.resid.to_frame()\n",
    "\n",
    "        # 2.1.1 Normalize residuals:\n",
    "        mean = residuals_df.mean()\n",
    "        std = residuals_df.std()\n",
    "        residuals_df_norm = residuals_df.copy()\n",
    "        residuals_df_norm = (residuals_df_norm[[\"resid\"]] - mean[0]) / std[0]\n",
    "\n",
    "        # 2.1.2 If the normalized residuals exceed +/- 3, then this is considered an outlier:\n",
    "        residuals_df_norm['is_outlier'] = np.where((residuals_df_norm['resid'] > 3) | (residuals_df_norm['resid'] < -3),\n",
    "                                                   True, False)\n",
    "        print(\n",
    "            f\"----------------------------------------\\n \\033[94m{residuals_df_norm['is_outlier'].value_counts()[True]} values (residuals) are dropped/imputed in {column}. \\033[0m\")\n",
    "\n",
    "        outliers_detection = residuals_df_norm[\"is_outlier\"]\n",
    "        outliers_detection = outliers_detection.to_frame(name=\"is_outlier\")\n",
    "        #plot exceeded residuals:\n",
    "        fig, ax = plt.subplots()\n",
    "        ax.scatter(residuals_df_norm.reset_index()[\"datetime\"], residuals_df_norm.reset_index()[\"resid\"],\n",
    "                   c=residuals_df_norm[\"is_outlier\"], cmap=cm.Set2, s=1)\n",
    "        ax.axhline(3, color=\"#e31a1c\")\n",
    "        ax.axhline(-3, color=\"#e31a1c\")\n",
    "        if display_plots != \"y\":\n",
    "            plt.close()\n",
    "        plt.show()\n",
    "\n",
    "        # 2.1.3 IMPUTATION: if needed\n",
    "        if pchip_imputation == \"y\":\n",
    "            print(\n",
    "                f\"---> PChip Imputation of {column}. It looks at outlier and puts a mathematical function over the dataset. The method estimates values that minimize overall curvature, thus obtaining a smooth surface passing through the input points. PChip interpolation is computationally efficient and can be used to interpolate large datasets quickly and accurately.\\nThe method returns an instance of the class Data (with the whole DataFrame with the (timeseries) cleaned column {column}). The physical impossible outliers are not cleaned in this method.\")\n",
    "            #IMPUTATION:\n",
    "            residuals_df_norm = residuals_df_norm.dropna()\n",
    "            residuals_df_imputed = residuals_df_norm.copy()\n",
    "            residuals_df_imputed['resid'] = np.where(\n",
    "                (residuals_df_imputed['resid'] > 3) | (residuals_df_imputed['resid'] < -3), np.nan,\n",
    "                residuals_df[\"resid\"].dropna())\n",
    "\n",
    "            residuals_cleaned = residuals_df_imputed[['resid']].interpolate(option=\"pchip\")  #pchip interpolation\n",
    "\n",
    "        elif pchip_imputation == \"delete\":\n",
    "            residuals_cleaned = residuals_df_norm[[\"resid\"]]\n",
    "\n",
    "        else:  #ASSUMING THAT ALL RESIDUALS WILL BE SET TO 3 or -3 (normalized) WHEN THEY ARE ABOVE 3 OR BELOW -3\n",
    "            print(\n",
    "                f\"---> Simple imputation of {column}: It looks at the normalized residuals and sets >3 values to 3 and <-3 values to -3.\\nThe method returns an instance of the class Data (with the whole DataFrame with the (timeseries) cleaned column {column}). The physical impossible outliers are not cleaned in this method.\")\n",
    "\n",
    "            residuals_df_norm = residuals_df_norm.dropna()\n",
    "            residuals_df_norm.loc[residuals_df_norm[\"resid\"] > 3, \"resid\"] = 3\n",
    "            residuals_df_norm.loc[residuals_df_norm[\"resid\"] < -3, \"resid\"] = -3\n",
    "            residuals_df_norm = residuals_df_norm.drop(columns=[\"is_outlier\"])\n",
    "\n",
    "            # De-Normalize (inverse of residuals_df_norm = (residuals_df_norm[[\"resid\"]] - mean[0])/std[0])\n",
    "            residuals_cleaned = residuals_df_norm.mul({\"resid\": std[0]}).add({\"resid\": mean[0]})\n",
    "\n",
    "        #Compose the Timeseries again (by adding the components residuals, seasonality and trend)\n",
    "        fig, ax = plt.subplots()\n",
    "        ax.scatter(residuals_cleaned.reset_index()[\"datetime\"], residuals_cleaned.reset_index()[\"resid\"], s=1)\n",
    "        if display_plots != \"y\":\n",
    "            plt.close()\n",
    "        plt.show()\n",
    "\n",
    "        #merging the timestamps of the 3 DataFrame's\n",
    "        data_cleaned = residuals_cleaned.join(seasonal_df).join(trend_df)\n",
    "        data_cleaned[column] = data_cleaned[\"seasonal\"] + data_cleaned[\"resid\"] + data_cleaned[\"trend\"]\n",
    "        #combine the data_cleaned (with 1 column) with the original dataframe\n",
    "        temp = self.dataframe.copy()\n",
    "        temp = temp.reset_index()\n",
    "        temp = temp.set_index(\"datetime\")\n",
    "        data_cleaned = data_cleaned.drop(columns=[\"seasonal\", \"trend\", \"resid\"]).join(temp, how=\"left\", lsuffix='left',\n",
    "                                                                                      rsuffix='right')\n",
    "\n",
    "        del data_cleaned[f\"{column}right\"]  #delete column\n",
    "\n",
    "        data_cleaned = data_cleaned.rename(columns={f\"{column}left\": column})\n",
    "\n",
    "        data_cleaned[\"is_outlier\"] = outliers_detection[\"is_outlier\"]\n",
    "\n",
    "        temp = None\n",
    "\n",
    "        #add Quality / delete:\n",
    "        if pchip_imputation == \"delete\":\n",
    "            data_cleaned = data_cleaned.drop(data_cleaned[data_cleaned[\"is_outlier\"] == True].index)\n",
    "        else:\n",
    "            data_cleaned[\"Quality\"] = np.where((data_cleaned['is_outlier'] == True), data_cleaned[\"Quality\"] + 1,\n",
    "                                               data_cleaned[\"Quality\"])\n",
    "            data_cleaned.loc[data_cleaned[\"Quality\"] > 1, \"Quality\"] = 1\n",
    "\n",
    "        try:\n",
    "            data_cleaned = data_cleaned.drop(columns=[\"is_outlier\"])\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        data_cleaned = data_cleaned.reset_index()\n",
    "        data_cleaned = data_cleaned.set_index(\"x\")\n",
    "        return Data(data_cleaned, self.name, set_index_datetime_int=\"n\")\n",
    "\n",
    "    def remove_outliers_temperature(self, skin_column_name=\"y\", bulk_column_name=\"y1\", airtemp_column_name=\"air_temp\",\n",
    "                                    imputation=\"y\"):\n",
    "\n",
    "        result_df = self.dataframe.copy()\n",
    "        # Remove any rows where either \"skinTemp\" or \"bulkTemp\" is above 35\n",
    "        result_df.loc[result_df[skin_column_name] >= 35, skin_column_name] = np.NaN\n",
    "        result_df.loc[result_df[skin_column_name] <= 0, skin_column_name] = np.NaN\n",
    "\n",
    "        #https://www.meteoswiss.admin.ch/climate/the-climate-of-switzerland/records-and-extremes (to filter out extremas in air temperature\n",
    "        result_df.loc[result_df[airtemp_column_name] >= 41.5, airtemp_column_name] = np.NaN\n",
    "        result_df.loc[result_df[airtemp_column_name] <= -41.8, airtemp_column_name] = np.NaN\n",
    "\n",
    "        result_df.loc[result_df[bulk_column_name] >= 35, bulk_column_name] = np.NaN\n",
    "        result_df.loc[result_df[bulk_column_name] <= 0, bulk_column_name] = np.NaN\n",
    "\n",
    "        print(\n",
    "            f\"----------------------------------------\\n \\033[94m{result_df[skin_column_name].isna().sum()} values are dropped/imputed in skin temperature of {self.name}.\\n{result_df[bulk_column_name].isna().sum()} values are dropped/imputed in bulk temperature  of {self.name}.\\n{result_df[airtemp_column_name].isna().sum()} values are dropped/imputed in air temperature  of {self.name}. \\033[0m\")\n",
    "\n",
    "        if imputation == \"y\":\n",
    "            #implement IMPUTATION here\n",
    "            print(\n",
    "                f\"---> PChip interpolation Imputation of skin and bulk temperature: Using a mathematical function, the method estimates values that minimize overall curvature, thus obtaining a smooth surface passing through the input points. \\nThe function returns a (Physical) cleaned DataFrame with the columns airtemp, skin & bulk temperature (physicaly) cleaned. The other parameters are not yet cleaned.\")\n",
    "\n",
    "            #IMPUTATION SPLINES Imputer:\n",
    "            result_df[\"Quality\"] = result_df.get(\"Quality\", 0)\n",
    "            result_df[\"Quality\"] = np.where((result_df.isna().any(axis=1)), result_df[\"Quality\"] + 1,\n",
    "                                            result_df[\"Quality\"])\n",
    "            result_df.loc[result_df[\"Quality\"] > 1, \"Quality\"] = 1\n",
    "            result_df[[skin_column_name]] = result_df[[skin_column_name]].interpolate(option=\"pchip\")\n",
    "            result_df[[bulk_column_name]] = result_df[[bulk_column_name]].interpolate(option=\"pchip\")\n",
    "            result_df[[airtemp_column_name]] = result_df[[airtemp_column_name]].interpolate(option=\"pchip\")\n",
    "\n",
    "        else:\n",
    "            print(\"The rows with physical impossible values are deleted.\")\n",
    "\n",
    "        result_df = result_df.dropna()  #to delete the nan (in pchip if e.g. the first value is a NaN, then the pchip interpolation can't handle this value)\n",
    "        try:\n",
    "            result_df = result_df.drop(columns=[\"is_outlier\"])\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        return Data(result_df, self.name, set_index_datetime_int=\"n\")\n",
    "\n",
    "    def remove_outliers_static(self, column_name, imputation=\"y\"):\n",
    "        # Calculate the z-score for the column\n",
    "        z_scores = np.abs(\n",
    "            (self.dataframe[column_name] - self.dataframe[column_name].mean()) / self.dataframe[column_name].std())\n",
    "        z_scores.loc[\n",
    "            z_scores == np.nan,] = 999  #will be later converted to nan again. this is used to have the same lengths\n",
    "\n",
    "        # filter the dataframe and replace <=3 values with NaN's (to further interpolate or drop)\n",
    "        result_clean = self.dataframe.copy()\n",
    "        result_clean[\"zscore\"] = z_scores.values\n",
    "\n",
    "        result_clean.loc[result_clean[\n",
    "                             \"zscore\"] > 3, column_name] = np.NaN  #when z-score is over 3, then the point will be an outlier\n",
    "        result_clean.loc[result_clean[\n",
    "                             \"zscore\"] < -3, column_name] = np.NaN  #when z-score is lower than  -3, then the point will be an outlier\n",
    "\n",
    "        print(\n",
    "            f\"----------------------------------------\\n\\033[94m{result_clean[column_name].isna().sum()} values are dropped/imputed in {column_name}.\\033[0m\")\n",
    "        if imputation == \"y\":\n",
    "            #implement IMPUTATION here\n",
    "            print(\n",
    "                f\"---> PChip interpolation Imputation of {column_name}: Using a mathematical function, the method estimates values that minimize overall curvature, thus obtaining a smooth surface passing through the input points. \\nThe function returns a (Physical) cleaned DataFrame with the column {column_name}(statically) cleaned. The other parameters are not yet cleaned.\")\n",
    "\n",
    "            #IMPUTATION pchip Imputer:\n",
    "            result_clean[\"Quality\"] = result_clean.get(\"Quality\", 0)\n",
    "            result_clean[\"Quality\"] = np.where((result_clean.isna().any(axis=1)), result_clean[\"Quality\"] + 1,\n",
    "                                               result_clean[\"Quality\"])\n",
    "            result_clean.loc[result_clean[\"Quality\"] > 1, \"Quality\"] = 1\n",
    "\n",
    "            result_clean[[column_name]] = result_clean[[column_name]].interpolate(option=\"pchip\")\n",
    "\n",
    "        else:\n",
    "            print(\"The rows with physical impossible values are deleted. \")\n",
    "\n",
    "        result_clean = result_clean.dropna()  #to delete the nan's (in pchip if e.g. the first value is a NaN, then the pchip interpolation can't handle this value)\n",
    "        try:\n",
    "            result_clean = result_clean.drop(columns=[\"is_outlier\"])\n",
    "        except:\n",
    "            pass\n",
    "        result_clean = result_clean.drop(columns=[\"zscore\"])\n",
    "        # Return the DataFrame with the cleaned column\n",
    "        return Data(result_clean, self.name, set_index_datetime_int=\"n\")\n",
    "\n",
    "    def rename_columns(self, columns={\"y\": \"skin_temp\", \"y1\": \"bulk_temp\"}):\n",
    "        self.dataframe.rename(columns=columns, inplace=True)\n",
    "        self.columns = self.dataframe.columns\n",
    "\n",
    "    def create_histogram(self, column_name):\n",
    "        sns.set_style(\"whitegrid\")\n",
    "        sns.histplot(self.dataframe[column_name], color=\"#fdbf6f\", kde=True, stat=\"density\", linewidth=4)\n",
    "        plt.title(f\"Histogram and KDE of the column {column_name} of {self.name}\")\n",
    "        plt.show()\n",
    "\n",
    "    def create_paiplot(self, column_names=[]):\n",
    "        if column_names == []:\n",
    "            column_names = self.columns.to_list()\n",
    "        sns.pairplot(self.dataframe[column_names], markers=\"o\", diag_kind=\"kde\", plot_kws={\"s\": 1, \"color\": \"red\"})\n",
    "        plt.show()\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "dataframe = pd.read_csv(\"./data/df_aegeri_skin.csv\")\n",
    "name = \"LakeAegeri\"\n",
    "LakeAegeri = Data(dataframe, name)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "def testing_all_things(x):\n",
    "    if x == True:\n",
    "        LakeAegeri.remove_outliers_static(\"y1\", imputation=\"y\")\n",
    "        LakeAegeri.remove_outliers_static(\"y1\", imputation=\"n\")\n",
    "        LakeAegeri.check_stationarity(\"y1\")\n",
    "        LakeAegeri.detect_outlier(\"y1\", pchip_imputation=\"y\")\n",
    "        LakeAegeri.detect_outlier(\"y1\", pchip_imputation=\"n\")\n",
    "        LakeAegeri.remove_outliers_temperature(skin_column_name=\"y\", bulk_column_name=\"y1\",\n",
    "                                               airtemp_column_name=\"air_temp\", imputation=\"n\")\n",
    "        LakeAegeri.remove_outliers_temperature(skin_column_name=\"y\", bulk_column_name=\"y1\",\n",
    "                                               airtemp_column_name=\"air_temp\", imputation=\"y\")\n",
    "        LakeAegeri.remove_outliers_static(\"y1\", imputation=\"y\")\n",
    "        LakeAegeri.remove_outliers_static(\"y1\", imputation=\"n\")\n",
    "        LakeAegeri.create_histogram(\"y1\")\n",
    "        LakeAegeri.create_paiplot()\n",
    "\n",
    "\n",
    "testing_all_things(False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Geneva BUC csv to big dataframe (FOR EXPORT THE DATAFRAME TO CSV FOR FURTHER INTERPRETATION)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "\n",
    "path = \"./data/Geneva/skin_temp/BUC_1m_csv\"\n",
    "\n",
    "all_files = glob.glob(os.path.join(path, \"*.csv\"))\n",
    "\n",
    "df = pd.concat((pd.read_csv(f) for f in all_files), ignore_index=True)\n",
    "df = df.set_index(\"x\")\n",
    "df_datetime = np.array([datetime.fromtimestamp(ts) for ts in df.index])\n",
    "df['datetime'] = df_datetime\n",
    "# x: time; y: Skin temp; y1: Rel hum; y2: Solar irrad; y3: wind speed; y4: wind dir; y5: rainfal; y6: air press\n",
    "df = df[[\"datetime\", \"y\", \"y1\", \"y2\", \"y3\", \"y4\", \"y5\", \"y6\"]]\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Do some plots:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "raw",
   "source": [
    "LakeAegeri.create_paiplot(column_names=[\"datetime\",\"bulk_temp\", 'skin_temp', 'air_temp', 'wind_speed', 'air_pressure',\n",
    "                                                'relative_humidity', 'solar_irradiance'])\n",
    "LakeAegeri.create_histogram(column_name=\"bulk_temp\")\n",
    "LakeAegeri.create_histogram(column_name=\"skin_temp\")\n",
    "LakeAegeri.create_histogram(column_name=\"air_temp\")\n",
    "LakeAegeri.create_histogram(column_name=\"solar_irradiance\")\n",
    "\n",
    "LakeAegeri.calc_rolling_statistics(\"bulk_temp\",window=144,show_plot=\"y\")\n",
    "LakeAegeri.calc_rolling_statistics(\"skin_temp\",window=144,show_plot=\"y\")\n",
    "LakeAegeri.calc_rolling_statistics(\"air_temp\",window=144,show_plot=\"y\")\n",
    "LakeAegeri.calc_rolling_statistics(\"solar_irradiance\",window=144,show_plot=\"y\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "raw",
   "source": [
    "LakeAegeri.calc_rolling_statistics(column=\"solar_irradiance\",window=1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## <span style=color:#7fc97f>Quality Flags</span>\n",
    "0A: Raw Data, downloaded from Datalakes with same timestamps\n",
    "\n",
    "1A: Physical Outlier corrected (imputed): New column with was_outlier(imputed)/no_outlier -> 1/0\n",
    "1B: Physical Outlier deleted\n",
    "\n",
    "2A: Time-Series corrected (and outlier corrected) (imputed): New column with was_outlier/no_outlier ->1/0\n",
    "2B: Time-Series (and physical) deleted\n",
    "\n",
    "3A: 2A + statistical outlier selection imputed -> New column with was_outlier/no_outlier ->1/0\n",
    "3B: 2B + statistical outlier selection deleted\n",
    "\n",
    "4A: Scaled Dataset (from 2A) for ML-Algorithms\n",
    "4B: Scaled Dataset (from 2B) for ML-Algorithms\n",
    "\n",
    "\n",
    "Naming of Datasets (CSV)\n",
    "Flag_LAKE.csv\n",
    "e.g. 0A_LakeAegeri.csv"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "#QualityFlags\n",
    "def gettime():\n",
    "    time_today = datetime.today().strftime(\"%y%m%d\")\n",
    "    return time_today\n",
    "\n",
    "\n",
    "def QualityFlag_create_0A(class_data, skin_column_name, bulk_column_name, airtemp_column_name, output=\"y\"):\n",
    "    try:\n",
    "        os.makedirs(f\"./data/cleaned_data/{gettime()}\")\n",
    "    except:\n",
    "        pass\n",
    "    get_filename = f\"{gettime()}_{class_data.name}_0A.csv\"\n",
    "    result = copy.deepcopy(class_data)\n",
    "    result.rename_columns(\n",
    "        columns={skin_column_name: \"skin_temp\", bulk_column_name: \"bulk_temp\", airtemp_column_name: \"air_temp\"})\n",
    "\n",
    "    if output == \"y\":\n",
    "        result.dataframe.to_csv(f\"./data/cleaned_data/{gettime()}/{get_filename}\")\n",
    "    return result\n",
    "\n",
    "\n",
    "def QualityFlag_create_1A(class_data, skin_column_name, bulk_column_name, airtemp_column_name, output=\"y\"):\n",
    "    try:\n",
    "        os.makedirs(f\"./data/cleaned_data/{gettime()}\")\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    get_filename = f\"{gettime()}_{class_data.name}_1A.csv\"\n",
    "    result = class_data.remove_outliers_temperature(skin_column_name=skin_column_name,\n",
    "                                                    bulk_column_name=bulk_column_name,\n",
    "                                                    airtemp_column_name=airtemp_column_name, imputation=\"y\")\n",
    "    result.rename_columns(\n",
    "        columns={skin_column_name: \"skin_temp\", bulk_column_name: \"bulk_temp\", airtemp_column_name: \"air_temp\"})\n",
    "\n",
    "    if output == \"y\":\n",
    "        result.dataframe.to_csv(f\"./data/cleaned_data/{gettime()}/{get_filename}\")\n",
    "    return result\n",
    "\n",
    "\n",
    "def QualityFlag_create_1B(class_data, skin_column_name, bulk_column_name, airtemp_column_name, output=\"y\"):\n",
    "    try:\n",
    "        os.makedirs(f\"./data/cleaned_data/{gettime()}\")\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    get_filename = f\"{gettime()}_{class_data.name}_1B.csv\"\n",
    "    result = class_data.remove_outliers_temperature(skin_column_name=skin_column_name,\n",
    "                                                    bulk_column_name=bulk_column_name,\n",
    "                                                    airtemp_column_name=airtemp_column_name, imputation=\"delete\")\n",
    "    result.rename_columns(\n",
    "        columns={skin_column_name: \"skin_temp\", bulk_column_name: \"bulk_temp\", airtemp_column_name: \"air_temp\"})\n",
    "    if output == \"y\":\n",
    "        result.dataframe.to_csv(f\"./data/cleaned_data/{gettime()}/{get_filename}\")\n",
    "    return result\n",
    "\n",
    "\n",
    "def QualityFlag_create_2A(class_data, skin_column_name, bulk_column_name, airtemp_column_name, period=144, output=\"y\"):\n",
    "    try:\n",
    "        os.makedirs(f\"./data/cleaned_data/{gettime()}\")\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    get_filename = f\"{gettime()}_{class_data.name}_2A.csv\"\n",
    "    result = class_data.remove_outliers_temperature(skin_column_name=skin_column_name,\n",
    "                                                    bulk_column_name=bulk_column_name,\n",
    "                                                    airtemp_column_name=airtemp_column_name, imputation=\"y\")\n",
    "    for i in [skin_column_name, bulk_column_name]:\n",
    "        result = result.detect_outlier(column=i, pchip_imputation=\"y\", PERIOD=period, display_plots=\"n\")\n",
    "    result.rename_columns(\n",
    "        columns={skin_column_name: \"skin_temp\", bulk_column_name: \"bulk_temp\", airtemp_column_name: \"air_temp\"})\n",
    "    if output == \"y\":\n",
    "        result.dataframe.to_csv(f\"./data/cleaned_data/{gettime()}/{get_filename}\")\n",
    "    return result\n",
    "\n",
    "\n",
    "def QualityFlag_create_2B(class_data, skin_column_name, bulk_column_name, airtemp_column_name, period=144, output=\"y\"):\n",
    "    try:\n",
    "        os.makedirs(f\"./data/cleaned_data/{gettime()}\")\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    get_filename = f\"{gettime()}_{class_data.name}_2B.csv\"\n",
    "    result = class_data.remove_outliers_temperature(skin_column_name=skin_column_name,\n",
    "                                                    bulk_column_name=bulk_column_name,\n",
    "                                                    airtemp_column_name=airtemp_column_name, imputation=\"delete\")\n",
    "    for i in [skin_column_name, bulk_column_name]:\n",
    "        result = result.detect_outlier(column=i, pchip_imputation=\"delete\", PERIOD=period, display_plots=\"n\")\n",
    "\n",
    "    result.rename_columns(\n",
    "        columns={skin_column_name: \"skin_temp\", bulk_column_name: \"bulk_temp\", airtemp_column_name: \"air_temp\"})\n",
    "\n",
    "    if output == \"y\":\n",
    "        result.dataframe.to_csv(f\"./data/cleaned_data/{gettime()}/{get_filename}\")\n",
    "    return result\n",
    "\n",
    "\n",
    "def QualityFlag_create_3A(class_data, skin_column_name, bulk_column_name, airtemp_column_name, output=\"y\"):\n",
    "    try:\n",
    "        os.makedirs(f\"./data/cleaned_data/{gettime()}\")\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    get_filename = f\"{gettime()}_{class_data.name}_3A.csv\"\n",
    "    result = QualityFlag_create_2B(class_data=class_data, skin_column_name=skin_column_name,\n",
    "                                   bulk_column_name=bulk_column_name, airtemp_column_name=airtemp_column_name,\n",
    "                                   output=\"no\")\n",
    "    #search elements for static method:\n",
    "    elements = []\n",
    "    for i in class_data.dataframe.columns:\n",
    "        if i not in [skin_column_name, bulk_column_name, airtemp_column_name, \"Quality\", \"datetime\", \"is_outlier\",\n",
    "                     \"meteo_timestamp\"]:\n",
    "            elements.append(i)\n",
    "            result = result.remove_outliers_static(column_name=i, imputation=\"y\")\n",
    "    print(f\"Static statistical method will be computed for following columns: {elements}\")\n",
    "    result.rename_columns(\n",
    "        columns={skin_column_name: \"skin_temp\", bulk_column_name: \"bulk_temp\", airtemp_column_name: \"air_temp\"})\n",
    "    if output == \"y\":\n",
    "        result.dataframe.to_csv(f\"./data/cleaned_data/{gettime()}/{get_filename}\")\n",
    "    return result\n",
    "\n",
    "\n",
    "def QualityFlag_create_3B(class_data, skin_column_name, bulk_column_name, airtemp_column_name, output=\"y\"):\n",
    "    try:\n",
    "        os.makedirs(f\"./data/cleaned_data/{gettime()}\")\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    get_filename = f\"{gettime()}_{class_data.name}_3B.csv\"\n",
    "    result = QualityFlag_create_2B(class_data=class_data, skin_column_name=skin_column_name,\n",
    "                                   bulk_column_name=bulk_column_name, airtemp_column_name=airtemp_column_name,\n",
    "                                   output=\"no\")\n",
    "    #search elements for static method:\n",
    "    elements = []\n",
    "    for i in class_data.dataframe.columns:\n",
    "        if i not in [skin_column_name, bulk_column_name, airtemp_column_name, \"Quality\", \"datetime\", \"is_outlier\",\n",
    "                     \"meteo_timestamp\"]:\n",
    "            elements.append(i)\n",
    "            result = result.remove_outliers_static(column_name=i, imputation=\"n\")\n",
    "\n",
    "    print(f\"Static statistical method will be computed for following columns: {elements}\")\n",
    "    result.rename_columns(\n",
    "        columns={skin_column_name: \"skin_temp\", bulk_column_name: \"bulk_temp\", airtemp_column_name: \"air_temp\"})\n",
    "\n",
    "    if output == \"y\":\n",
    "        result.dataframe.to_csv(f\"./data/cleaned_data/{gettime()}/{get_filename}\")\n",
    "    return result\n",
    "\n",
    "\n",
    "def QualityFlag_create_4A(class_data, skin_column_name, bulk_column_name, airtemp_column_name):\n",
    "    try:\n",
    "        os.makedirs(f\"./data/cleaned_data/{gettime()}\")\n",
    "    except:\n",
    "        pass\n",
    "    data = QualityFlag_create_3A(class_data=class_data, skin_column_name=skin_column_name,\n",
    "                                 bulk_column_name=bulk_column_name, airtemp_column_name=airtemp_column_name,\n",
    "                                 output=\"no\")\n",
    "\n",
    "    data = data.dataframe.drop(columns=[\"datetime\"])\n",
    "    try:\n",
    "        data = data.dataframe.drop(column=[\"meteo_timestamp\"])\n",
    "    except:\n",
    "        pass\n",
    "    scaler = RobustScaler()\n",
    "    scaled_data = scaler.fit_transform(data)\n",
    "    scaled_df = pd.DataFrame(scaled_data, columns=data.columns)\n",
    "    scaled_df.rename(\n",
    "        columns={skin_column_name: \"skin_temp\", bulk_column_name: \"bulk_temp\", airtemp_column_name: \"air_temp\"})\n",
    "\n",
    "    with open(f\"./data/cleaned_data/{gettime()}/{gettime()}_{class_data.name}_4A_scaled_data.npy\", \"wb\") as f:\n",
    "        np.save(f,scaler.center_)\n",
    "        np.save(f,scaler.scale_)\n",
    "\n",
    "    get_filename = f\"{gettime()}_{class_data.name}_4A.csv\"\n",
    "    scaled_df.to_csv(f\"./data/cleaned_data/{gettime()}/{get_filename}\", index=False)\n",
    "    return scaled_df\n",
    "\n",
    "\n",
    "def QualityFlag_create_4B(class_data, skin_column_name, bulk_column_name, airtemp_column_name):\n",
    "    try:\n",
    "        os.makedirs(f\"./data/cleaned_data/{gettime()}\")\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    data = QualityFlag_create_3B(class_data=class_data, skin_column_name=skin_column_name,\n",
    "                                 bulk_column_name=bulk_column_name, airtemp_column_name=airtemp_column_name,\n",
    "                                 output=\"no\")\n",
    "    data = data.dataframe.drop(columns=[\"datetime\"])\n",
    "    try:\n",
    "        data = data.dataframe.drop(column=[\"meteo_timestamp\"])\n",
    "    except:\n",
    "        pass\n",
    "    scaler = RobustScaler()\n",
    "    scaled_data = scaler.fit_transform(data)\n",
    "    scaled_df = pd.DataFrame(scaled_data, columns=data.columns)\n",
    "    scaled_df.rename(\n",
    "        columns={skin_column_name: \"skin_temp\", bulk_column_name: \"bulk_temp\", airtemp_column_name: \"air_temp\"})\n",
    "\n",
    "    with open(f\"./data/cleaned_data/{gettime()}/{gettime()}_{class_data.name}_4B_scaled_data.npy\", \"wb\") as f:\n",
    "        np.save(f,scaler.center_)\n",
    "        np.save(f,scaler.scale_)\n",
    "\n",
    "    get_filename = f\"{gettime()}_{class_data.name}_4B.csv\"\n",
    "    scaled_df.to_csv(f\"./data/cleaned_data/{gettime()}/{get_filename}\", index=False)\n",
    "    return scaled_df\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      " \u001B[94m1057 values are dropped/imputed in skin temperature of LakeAegeri.\n",
      "739 values are dropped/imputed in bulk temperature  of LakeAegeri.\n",
      "1 values are dropped/imputed in air temperature  of LakeAegeri. \u001B[0m\n",
      "---> Spline interpolation Imputation of skin and bulk temperature: Using a mathematical function, the method estimates values that minimize overall curvature, thus obtaining a smooth surface passing through the input points. \n",
      "The function returns a (Physical) cleaned DataFrame with the columns airtemp, skin & bulk temperature (physicaly) cleaned. The other parameters are not yet cleaned.\n",
      "----------------------------------------\n",
      " \u001B[94m1057 values are dropped/imputed in skin temperature of LakeAegeri.\n",
      "739 values are dropped/imputed in bulk temperature  of LakeAegeri.\n",
      "1 values are dropped/imputed in air temperature  of LakeAegeri. \u001B[0m\n",
      "The rows with physical impossible values are deleted.\n",
      "----------------------------------------\n",
      " \u001B[94m1057 values are dropped/imputed in skin temperature of LakeAegeri.\n",
      "739 values are dropped/imputed in bulk temperature  of LakeAegeri.\n",
      "1 values are dropped/imputed in air temperature  of LakeAegeri. \u001B[0m\n",
      "---> Spline interpolation Imputation of skin and bulk temperature: Using a mathematical function, the method estimates values that minimize overall curvature, thus obtaining a smooth surface passing through the input points. \n",
      "The function returns a (Physical) cleaned DataFrame with the columns airtemp, skin & bulk temperature (physicaly) cleaned. The other parameters are not yet cleaned.\n",
      "----------------------------------------\n",
      " \u001B[94m355 values (residuals) are dropped/imputed in y. \u001B[0m\n",
      "---> Splines Imputation of y. It looks at outlier and puts a mathematical function over the dataset. The method estimates values that minimize overall curvature, thus obtaining a smooth surface passing through the input points. Spline interpolation is computationally efficient and can be used to interpolate large datasets quickly and accurately.\n",
      "The method returns an instance of the class Data (with the whole DataFrame with the (timeseries) cleaned column y). The physical impossible outliers are not cleaned in this method.\n",
      "----------------------------------------\n",
      " \u001B[94m317 values (residuals) are dropped/imputed in y1. \u001B[0m\n",
      "---> Splines Imputation of y1. It looks at outlier and puts a mathematical function over the dataset. The method estimates values that minimize overall curvature, thus obtaining a smooth surface passing through the input points. Spline interpolation is computationally efficient and can be used to interpolate large datasets quickly and accurately.\n",
      "The method returns an instance of the class Data (with the whole DataFrame with the (timeseries) cleaned column y1). The physical impossible outliers are not cleaned in this method.\n",
      "----------------------------------------\n",
      " \u001B[94m1057 values are dropped/imputed in skin temperature of LakeAegeri.\n",
      "739 values are dropped/imputed in bulk temperature  of LakeAegeri.\n",
      "1 values are dropped/imputed in air temperature  of LakeAegeri. \u001B[0m\n",
      "The rows with physical impossible values are deleted.\n",
      "----------------------------------------\n",
      " \u001B[94m372 values (residuals) are dropped/imputed in y. \u001B[0m\n",
      "----------------------------------------\n",
      " \u001B[94m291 values (residuals) are dropped/imputed in y1. \u001B[0m\n",
      "----------------------------------------\n",
      " \u001B[94m1057 values are dropped/imputed in skin temperature of LakeAegeri.\n",
      "739 values are dropped/imputed in bulk temperature  of LakeAegeri.\n",
      "1 values are dropped/imputed in air temperature  of LakeAegeri. \u001B[0m\n",
      "The rows with physical impossible values are deleted.\n",
      "----------------------------------------\n",
      " \u001B[94m372 values (residuals) are dropped/imputed in y. \u001B[0m\n",
      "----------------------------------------\n",
      " \u001B[94m291 values (residuals) are dropped/imputed in y1. \u001B[0m\n",
      "----------------------------------------\n",
      "\u001B[94m314 values are dropped/imputed in wind_speed.\u001B[0m\n",
      "---> Spline interpolation Imputation of wind_speed: Using a mathematical function, the method estimates values that minimize overall curvature, thus obtaining a smooth surface passing through the input points. \n",
      "The function returns a (Physical) cleaned DataFrame with the column wind_speed(statically) cleaned. The other parameters are not yet cleaned.\n",
      "----------------------------------------\n",
      "\u001B[94m69 values are dropped/imputed in air_pressure.\u001B[0m\n",
      "---> Spline interpolation Imputation of air_pressure: Using a mathematical function, the method estimates values that minimize overall curvature, thus obtaining a smooth surface passing through the input points. \n",
      "The function returns a (Physical) cleaned DataFrame with the column air_pressure(statically) cleaned. The other parameters are not yet cleaned.\n",
      "----------------------------------------\n",
      "\u001B[94m174 values are dropped/imputed in relative_humidity.\u001B[0m\n",
      "---> Spline interpolation Imputation of relative_humidity: Using a mathematical function, the method estimates values that minimize overall curvature, thus obtaining a smooth surface passing through the input points. \n",
      "The function returns a (Physical) cleaned DataFrame with the column relative_humidity(statically) cleaned. The other parameters are not yet cleaned.\n",
      "----------------------------------------\n",
      "\u001B[94m428 values are dropped/imputed in solar_irradiance.\u001B[0m\n",
      "---> Spline interpolation Imputation of solar_irradiance: Using a mathematical function, the method estimates values that minimize overall curvature, thus obtaining a smooth surface passing through the input points. \n",
      "The function returns a (Physical) cleaned DataFrame with the column solar_irradiance(statically) cleaned. The other parameters are not yet cleaned.\n",
      "Static statistical method will be computed for following columns: ['wind_speed', 'air_pressure', 'relative_humidity', 'solar_irradiance']\n",
      "----------------------------------------\n",
      " \u001B[94m1057 values are dropped/imputed in skin temperature of LakeAegeri.\n",
      "739 values are dropped/imputed in bulk temperature  of LakeAegeri.\n",
      "1 values are dropped/imputed in air temperature  of LakeAegeri. \u001B[0m\n",
      "The rows with physical impossible values are deleted.\n",
      "----------------------------------------\n",
      " \u001B[94m372 values (residuals) are dropped/imputed in y. \u001B[0m\n",
      "----------------------------------------\n",
      " \u001B[94m291 values (residuals) are dropped/imputed in y1. \u001B[0m\n",
      "----------------------------------------\n",
      "\u001B[94m314 values are dropped/imputed in wind_speed.\u001B[0m\n",
      "The rows with physical impossible values are deleted. \n",
      "----------------------------------------\n",
      "\u001B[94m74 values are dropped/imputed in air_pressure.\u001B[0m\n",
      "The rows with physical impossible values are deleted. \n",
      "----------------------------------------\n",
      "\u001B[94m142 values are dropped/imputed in relative_humidity.\u001B[0m\n",
      "The rows with physical impossible values are deleted. \n",
      "----------------------------------------\n",
      "\u001B[94m412 values are dropped/imputed in solar_irradiance.\u001B[0m\n",
      "The rows with physical impossible values are deleted. \n",
      "Static statistical method will be computed for following columns: ['wind_speed', 'air_pressure', 'relative_humidity', 'solar_irradiance']\n",
      "----------------------------------------\n",
      " \u001B[94m1057 values are dropped/imputed in skin temperature of LakeAegeri.\n",
      "739 values are dropped/imputed in bulk temperature  of LakeAegeri.\n",
      "1 values are dropped/imputed in air temperature  of LakeAegeri. \u001B[0m\n",
      "The rows with physical impossible values are deleted.\n",
      "----------------------------------------\n",
      " \u001B[94m372 values (residuals) are dropped/imputed in y. \u001B[0m\n",
      "----------------------------------------\n",
      " \u001B[94m291 values (residuals) are dropped/imputed in y1. \u001B[0m\n",
      "----------------------------------------\n",
      "\u001B[94m314 values are dropped/imputed in wind_speed.\u001B[0m\n",
      "---> Spline interpolation Imputation of wind_speed: Using a mathematical function, the method estimates values that minimize overall curvature, thus obtaining a smooth surface passing through the input points. \n",
      "The function returns a (Physical) cleaned DataFrame with the column wind_speed(statically) cleaned. The other parameters are not yet cleaned.\n",
      "----------------------------------------\n",
      "\u001B[94m69 values are dropped/imputed in air_pressure.\u001B[0m\n",
      "---> Spline interpolation Imputation of air_pressure: Using a mathematical function, the method estimates values that minimize overall curvature, thus obtaining a smooth surface passing through the input points. \n",
      "The function returns a (Physical) cleaned DataFrame with the column air_pressure(statically) cleaned. The other parameters are not yet cleaned.\n",
      "----------------------------------------\n",
      "\u001B[94m174 values are dropped/imputed in relative_humidity.\u001B[0m\n",
      "---> Spline interpolation Imputation of relative_humidity: Using a mathematical function, the method estimates values that minimize overall curvature, thus obtaining a smooth surface passing through the input points. \n",
      "The function returns a (Physical) cleaned DataFrame with the column relative_humidity(statically) cleaned. The other parameters are not yet cleaned.\n",
      "----------------------------------------\n",
      "\u001B[94m428 values are dropped/imputed in solar_irradiance.\u001B[0m\n",
      "---> Spline interpolation Imputation of solar_irradiance: Using a mathematical function, the method estimates values that minimize overall curvature, thus obtaining a smooth surface passing through the input points. \n",
      "The function returns a (Physical) cleaned DataFrame with the column solar_irradiance(statically) cleaned. The other parameters are not yet cleaned.\n",
      "Static statistical method will be computed for following columns: ['wind_speed', 'air_pressure', 'relative_humidity', 'solar_irradiance']\n",
      "----------------------------------------\n",
      " \u001B[94m1057 values are dropped/imputed in skin temperature of LakeAegeri.\n",
      "739 values are dropped/imputed in bulk temperature  of LakeAegeri.\n",
      "1 values are dropped/imputed in air temperature  of LakeAegeri. \u001B[0m\n",
      "The rows with physical impossible values are deleted.\n",
      "----------------------------------------\n",
      " \u001B[94m372 values (residuals) are dropped/imputed in y. \u001B[0m\n",
      "----------------------------------------\n",
      " \u001B[94m291 values (residuals) are dropped/imputed in y1. \u001B[0m\n",
      "----------------------------------------\n",
      "\u001B[94m314 values are dropped/imputed in wind_speed.\u001B[0m\n",
      "The rows with physical impossible values are deleted. \n",
      "----------------------------------------\n",
      "\u001B[94m74 values are dropped/imputed in air_pressure.\u001B[0m\n",
      "The rows with physical impossible values are deleted. \n",
      "----------------------------------------\n",
      "\u001B[94m142 values are dropped/imputed in relative_humidity.\u001B[0m\n",
      "The rows with physical impossible values are deleted. \n",
      "----------------------------------------\n",
      "\u001B[94m412 values are dropped/imputed in solar_irradiance.\u001B[0m\n",
      "The rows with physical impossible values are deleted. \n",
      "Static statistical method will be computed for following columns: ['wind_speed', 'air_pressure', 'relative_humidity', 'solar_irradiance']\n"
     ]
    }
   ],
   "source": [
    "a=QualityFlag_create_0A(class_data=LakeAegeri, skin_column_name=\"y\", bulk_column_name=\"y1\",\n",
    "                      airtemp_column_name=\"air_temp\")\n",
    "b=QualityFlag_create_1A(class_data=LakeAegeri, skin_column_name=\"y\", bulk_column_name=\"y1\",\n",
    "                      airtemp_column_name=\"air_temp\")\n",
    "c=QualityFlag_create_1B(class_data=LakeAegeri, skin_column_name=\"y\", bulk_column_name=\"y1\",\n",
    "                      airtemp_column_name=\"air_temp\")\n",
    "d=QualityFlag_create_2A(class_data=LakeAegeri, skin_column_name=\"y\", bulk_column_name=\"y1\",\n",
    "                      airtemp_column_name=\"air_temp\")\n",
    "e=QualityFlag_create_2B(class_data=LakeAegeri, skin_column_name=\"y\", bulk_column_name=\"y1\",\n",
    "                      airtemp_column_name=\"air_temp\")\n",
    "f=QualityFlag_create_3A(class_data=LakeAegeri, skin_column_name=\"y\", bulk_column_name=\"y1\",\n",
    "                      airtemp_column_name=\"air_temp\")\n",
    "g=QualityFlag_create_3B(class_data=LakeAegeri, skin_column_name=\"y\", bulk_column_name=\"y1\",\n",
    "                      airtemp_column_name=\"air_temp\")\n",
    "h=QualityFlag_create_4A(class_data=LakeAegeri, skin_column_name=\"y\", bulk_column_name=\"y1\",\n",
    "                      airtemp_column_name=\"air_temp\")\n",
    "f=QualityFlag_create_4B(class_data=LakeAegeri, skin_column_name=\"y\", bulk_column_name=\"y1\",\n",
    "                      airtemp_column_name=\"air_temp\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# RESCALE 4A/4B INFO"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "all_files = os.listdir(\"./data/cleaned_data/230422\")\n",
    "csv_files = list(filter(lambda f: f.endswith('.csv'), all_files))\n",
    "\n",
    "# lambda returns True if filename (within `all_files`) ends with .csv or else False\n",
    "# and filter function uses the returned boolean value to filter .csv files from list files.\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "# Load the scaled data in another Dataframe\n",
    "scaled_df = pd.read_csv(\"./data/cleaned_data/230422/230422_LakeAegeri_4B.csv\")\n",
    "\n",
    "# Load the scaling information\n",
    "with open(\"./data/cleaned_data/230422/230422_LakeAegeri_4B_scaled_data.npy\", \"rb\") as f:\n",
    "    center_saved=np.load(f)\n",
    "    scale_saved=np.load(f)\n",
    "\n",
    "# Instantiate the scaler object with the saved scaling information\n",
    "scaler = RobustScaler(with_centering=True, with_scaling=True)\n",
    "temp=scaler.fit(scaled_df)\n",
    "scaler.center_ = center_saved\n",
    "scaler.scale_ = scale_saved\n",
    "del temp\n",
    "# Transform the data using the scaler object\n",
    "scaled_data = scaler.transform(scaled_df)\n",
    "# Convert the numpy array back to a pandas DataFrame\n",
    "unscaled_df = pd.DataFrame(scaled_data, columns=scaled_df.columns)"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
